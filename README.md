# inference-Time
LivePortrait is an innovative portrait animation framework designed to transform static images into lifelike videos with high efficiency and precise control. Unlike diffusion-based methods, LivePortrait employs an implicit-keypoint-based approach, balancing computational efficiency with controllability.
researchgate.net
+3
arxiv.org
+3
arxiv.org
+3
youtube.com
+6
paperswithcode.com
+6
liveportrait.github.io
+6

üîç Key Features
Implicit Keypoint Framework: Utilizes compact implicit keypoints to represent facial movements, enabling efficient animation without explicit 3D modeling.
arxiv.org
+4
paperswithcode.com
+4
arxiv.org
+4

Stitching and Retargeting Modules: Introduces specialized modules for seamless integration of animated features and precise control over facial expressions, such as eye and lip movements.
themoonlight.io
+1
themoonlight.io
+1

Scalable Training: Trained on approximately 69 million high-quality frames using a mixed image-video strategy, enhancing generalization across diverse subjects and styles.
themoonlight.io
+5
liveportrait.github.io
+5
paperswithcode.com
+5

High Performance: Achieves real-time animation speeds of approximately 12.8 milliseconds per frame on an RTX 4090 GPU.
arxiv.org
+3
arxiv.org
+3
liveportrait.github.io
+3

Versatility: Capable of animating not only human portraits but also animals like cats, dogs, and pandas through fine-tuning.
liveportrait.github.io
+1
github.com
+1

üìÑ Access and Resources
Project Page: Explore LivePortrait's features and demonstrations at liveportrait.github.io.

GitHub Repository: Access the official codebase and models at github.com/KwaiVGI/LivePortrait.
arxiv.org
+4
github.com
+4
liveportrait.github.io
+4

Research Paper: Read the detailed methodology and evaluations in the paper LivePortrait: Efficient Portrait Animation with Stitching and Retargeting Control.
github.com

Interactive Demo: Try LivePortrait directly in your browser via the Hugging Face Space.
huggingface.co
+1
github.com
+1

